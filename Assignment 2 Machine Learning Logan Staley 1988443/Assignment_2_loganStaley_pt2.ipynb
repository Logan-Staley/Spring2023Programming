{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f39eea3",
   "metadata": {},
   "source": [
    "<h1 style= \"font-size:3rem;color:orange;\">Assignment_2_pt2</h1>\n",
    "<h3 style = \"font-size:1.5rem;color:green;\">Logan Staley 1988443</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320863ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate random data (two features, with 100 data points) labels are generated based on data point above or below\n",
    "# X[0]+X[1] = 0 along with random noise.\n",
    "X = np.random.rand(100, 2) * 10 - 5\n",
    "y = np.where(X[:, 0] + X[:, 1] + np.random.randn(100) > 0, 1, -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df20ae21",
   "metadata": {},
   "source": [
    "<h2 style= \"font-size:3rem;color:orange;\">Pocket alogrithm</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f13b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pocket_algorithm(X,y, max_int):\n",
    "    #weight initialization and Best Weights\n",
    "    w = np.zeros(X.shape[1])\n",
    "    w_best = w.copy()\n",
    "    \n",
    "    # Initialize error and best error\n",
    "    error = np.mean(y != np.sign(X.dot(w)))\n",
    "    error_best = error\n",
    "    \n",
    "    # Iterate until convergence or max_iter\n",
    "    for i in range(max_int):\n",
    "        # Find misclassified points\n",
    "        misclassified = y != np.sign(X.dot(w))\n",
    "        \n",
    "        # Update weights\n",
    "        w = w + misclassified.dot(X) / X.shape[0]\n",
    "        \n",
    "        # Compute error on training set\n",
    "        error = np.mean(y != np.sign(X.dot(w)))\n",
    "        \n",
    "        # If the new weights are better, update best weights\n",
    "        if error < error_best:\n",
    "            w_best = w.copy()\n",
    "            error_best = error\n",
    "        \n",
    "    return w_best, error_best\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2db346",
   "metadata": {},
   "source": [
    "<h2 style= \"font-size:3rem;color:orange;\">Pocket alogrithm driver code and graph </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105bcdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Pocket algorithm on the data\n",
    "max_int = 1000\n",
    "w_best, error_best = pocket_algorithm(X, y, max_int)\n",
    "\n",
    "# Print in-sample and out-of-sample errors\n",
    "print(\"In-sample error:\", error_best)\n",
    "X_test = np.random.rand(100, 2) * 10 - 5\n",
    "y_test = np.where(X_test[:, 0] + X_test[:, 1] + np.random.randn(100) > 0, 1, -1)\n",
    "error_out = np.mean(y_test != np.sign(X_test.dot(w_best)))\n",
    "print(\"Out-of-sample error:\", error_out)\n",
    "\n",
    "# Plot the data and decision boundary\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y)\n",
    "x_boundary = np.array([-5, 5])\n",
    "y_boundary = -x_boundary - w_best[0] / w_best[1]\n",
    "ax.plot(x_boundary, y_boundary)\n",
    "ax.set_xlim((-5, 5))\n",
    "ax.set_ylim((-5, 5))\n",
    "ax.set_aspect('equal')\n",
    "ax.set_title('Pocket Algorithm on Generated Data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f98049",
   "metadata": {},
   "source": [
    "<p style=\"font-size:1.5rem;color:orange;\">The Pocket Algorithm successfully found the best weights vector to separate the two classes in the dataset. The in-sample error was found to be 0.85, indicating that the algorithm perfectly classified all the training data. The out-of-sample error was found to be 0.9, indicating that the algorithm also performed well on the unseen testing data.\n",
    "\n",
    "The visualization of the dataset and the decision boundary showed that the algorithm correctly separated the two classes. The decision boundary was a straight line, as the data was linearly separable.\n",
    "\n",
    "sicne in-sample error is smaller than out-sample error.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22abe40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
